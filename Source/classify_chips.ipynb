{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, metrics, model_selection\n",
    "\n",
    "from tensorflow.python.keras.applications import ResNet50\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Conv2D, MaxPooling2D, Dropout\n",
    "\n",
    "np.random.seed(2019)\n",
    "data_dir = os.path.join('..', 'Data', 'Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read all the data into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all the data files\n",
    "data_files = glob.glob(os.path.join(data_dir, '*.png'))\n",
    "\n",
    "# Read the first image to get the size\n",
    "test_img = cv2.imread(data_files[0])\n",
    "img_size = test_img.shape[0:2]\n",
    "\n",
    "# Initialize data elements (avoids resizing later)\n",
    "X = np.zeros((len(data_files), img_size[0], img_size[1]))\n",
    "y = np.zeros(len(data_files))\n",
    "\n",
    "# Step through all the files\n",
    "current_idx = 0;\n",
    "for fs in data_files:\n",
    "    # Parse the filename (we only really care about extracting the object class)\n",
    "    x = re.search(\"\\d+\\.\\d+\\.(\\S+)\\.png\", fs)\n",
    "    \n",
    "    # Read the file\n",
    "    img = cv2.imread(fs)\n",
    "    img = np.squeeze(img[:,:,1]) # select the first color channel\n",
    "    \n",
    "    if (x.group(1) == '1'): # \"Car\"\n",
    "        X[current_idx,:,:] = img\n",
    "        y[current_idx] = 1\n",
    "        current_idx += 1\n",
    "    elif(x.group(1) == 'bg'): # Background\n",
    "        X[current_idx,:,:] = img\n",
    "        y[current_idx] = 0\n",
    "        current_idx += 1\n",
    "\n",
    "num_cars = np.count_nonzero(y==1)\n",
    "num_bg = np.count_nonzero(y==0)\n",
    "print(\"found {} cars and {} background images\".format(num_cars, num_bg))\n",
    "\n",
    "# Equalize the class probabilities for training (delete a random subset)\n",
    "# We do this now and not earlier because we don't know fully what we are going to get out of the directory apriori\n",
    "num_bg_to_delete = np.round(0).astype('int')\n",
    "if (num_bg_to_delete):\n",
    "    print(\"Deleting \", num_bg_to_delete, \" background images\")\n",
    "    bg_idx = np.nonzero(y==0)[0]\n",
    "    np.random.shuffle(bg_idx)\n",
    "    to_delete = bg_idx[0:num_bg_to_delete]\n",
    "    y = np.delete(y,to_delete)\n",
    "    X = np.delete(X,to_delete, axis=0)\n",
    "    \n",
    "num_cars = np.count_nonzero(y==1)\n",
    "num_bg = np.count_nonzero(y==0)\n",
    "print(\"After class equalization, there are {} cars and {} background images\".format(num_cars, num_bg))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_to_show = 25\n",
    "imgs_per_col = 5\n",
    "for i in range(0, imgs_to_show):\n",
    "    plt.subplot(imgs_to_show/imgs_per_col, imgs_per_col, i+1)\n",
    "    plt.imshow(X[i,:,:], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(y[i])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_float = X.astype('float32')\n",
    "X_float /= 255\n",
    "\n",
    "print(X_float[0,:,:].max())\n",
    "print(X_float[0,:,:].min())\n",
    "plt.figure(figsize=(10,10)) \n",
    "plt.imshow(X_float[0,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_flat = X.reshape((len(X), -1))\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_flat, y, test_size=0.25, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    {'kernel':['rbf'], 'gamma':np.logspace(-8, -5, 10)}\n",
    "]\n",
    "clf=svm.SVC(probability=True)\n",
    "cv_clf=model_selection.GridSearchCV(estimator=clf, param_grid=parameters, cv=4, n_jobs=-1);\n",
    "cv_clf.fit(X_train,y_train)\n",
    "print(\"Best estimator:\\n\", cv_clf.best_estimator_)\n",
    "\n",
    "#Check performance\n",
    "y_pred = cv_clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy score:\\n\", metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred[0:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_for_cnn = X_float\n",
    "print(X_for_cnn.shape)\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(X_for_cnn.reshape(X_for_cnn.shape[0], X_for_cnn.shape[1], X_for_cnn.shape[2], 1), y, test_size=0.20, random_state=23)\n",
    "input_shape = (x_train.shape[1], x_train.shape[2], 1)\n",
    "print(input_shape)\n",
    "\n",
    "plt.imshow(x_train[0,:,:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv2D(filters=32, kernel_size=(4,4), input_shape=input_shape))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_model.add(Conv2D(filters=32, kernel_size=(4,4)))\n",
    "cnn_model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "cnn_model.add(Dense(128, activation='relu'))\n",
    "cnn_model.add(Dropout(0.2))\n",
    "cnn_model.add(Dense(2,activation='softmax'))\n",
    "cnn_model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "cnn_model.fit(x=x_train,y=y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision/recall plotting was taken from the [scikit-learn documentation](https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cnn_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "y_test_hat = cnn_model.predict(x_test)[:,1]\n",
    "print(y_test_hat.shape)\n",
    "print(y_test_hat[1:10])\n",
    "print(y_test[1:10])\n",
    "precision, recall, _ = metrics.precision_recall_curve(y_test, y_test_hat)\n",
    "step_kwargs = {'step': 'post'}\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = cnn_model.predict(x_test)\n",
    "for i in range(0, len(y_test)):\n",
    "    if np.argmax(y_hat[i,:]) != y_test[i]:\n",
    "        print(\"Guessed \", np.argmax(y_hat[i,:]), \" was \", y_test[i], \" probs\", y_hat[i,:])\n",
    "        plt.imshow(np.squeeze(x_test[i,:,:,:]), cmap='gray');\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning from ResNet50\n",
    "[Kaggle Example](https://www.kaggle.com/dansbecker/transfer-learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_color = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
    "X_color = np.tile(X_color, (1,1,1,3))\n",
    "X_color /= 3\n",
    "print(type(X_color[0,0,0,0]))\n",
    "print(X_color.shape)\n",
    "plt.imshow(X_color[0,:,:,:])\n",
    "plt.show()\n",
    "                  \n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(X_color, y, test_size=0.25, random_state=23)\n",
    "input_shape = (x_train.shape[1], x_train.shape[2], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model = Sequential()\n",
    "transfer_model.add(ResNet50(include_top=False, input_shape=input_shape, pooling='avg', weights='imagenet'))\n",
    "transfer_model.add(Dense(2,activation='softmax'))\n",
    "transfer_model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model.compile(optimizer='sgd', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "transfer_model.fit(x=x_train,y=y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = transfer_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a classifier on a full image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation import run_sliding_window\n",
    "\n",
    "img_dir = os.path.join('..', 'Data', 'Vehicules1024')\n",
    "\n",
    "test_img = cv2.imread(os.path.join(img_dir, \"00000014_ir.png\" ), cv2.IMREAD_GRAYSCALE)\n",
    "print(type(test_img[0,0]))\n",
    "plt.figure(figsize=(10,10)) \n",
    "plt.imshow(test_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitioned_image, bboxes_vertices = run_sliding_window(test_img, 8, 64, 64)\n",
    "partitioned_image_flat = partitioned_image.reshape((-1, 64, 64, 1))\n",
    "\n",
    "partitioned_image_for_svm = partitioned_image_flat.reshape((-1, 64*64))\n",
    "\n",
    "partitioned_image_for_cnn = partitioned_image_flat.astype('float32')\n",
    "partitioned_image_for_cnn /= 255\n",
    "\n",
    "partitioned_image_for_transfer = np.tile(partitioned_image_flat.astype('float64'), (1,1,1,3))\n",
    "partitioned_image_for_transfer /= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_flat = cv_clf.predict(partitioned_image_for_svm)\n",
    "class_flat = cnn_model.predict(partitioned_image_for_cnn)[:,1]\n",
    "#class_flat = transfer_model.predict(partitioned_image_for_transfer)[:,1]\n",
    "class_img = class_flat.reshape((partitioned_image.shape[0], partitioned_image.shape[1]))\n",
    "plt.figure(figsize=(10,10)) \n",
    "plt.imshow(class_img, cmap='magma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_img_thresh = class_img>0.9\n",
    "plt.imshow(class_img_thresh, cmap='magma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-maximal supression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import non_maximal_suppression\n",
    "bboxes_array = np.asarray(bboxes_vertices).reshape((-1,4))\n",
    "picked_boxes = non_maximal_suppression.do_non_max_suppression(bboxes_array, class_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
