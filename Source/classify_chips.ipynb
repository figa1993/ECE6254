{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, metrics, model_selection\n",
    "\n",
    "from tensorflow.python.keras.applications import ResNet50\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Conv2D, MaxPooling2D, Dropout\n",
    "\n",
    "import plot_support\n",
    "\n",
    "#training_dir = os.path.join('..', 'Data', 'Training')\n",
    "#data_dir = os.path.join('..', 'Data', 'Vehicules1024')\n",
    "\n",
    "training_dir = os.path.join('..', 'Data', 'Training_pre')\n",
    "data_dir = os.path.join('..', 'Data', 'Preprocessed')\n",
    "\n",
    "run_pixel_svm   = True\n",
    "run_feature_svm = False\n",
    "run_cnn         = True\n",
    "run_resnet      = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read all the data into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all the data files\n",
    "training_files = glob.glob(os.path.join(training_dir, '*.png'))\n",
    "\n",
    "# Read the first image to get the size\n",
    "test_img = cv2.imread(training_files[0])\n",
    "img_size = test_img.shape[0:2]\n",
    "\n",
    "# Initialize data elements (avoids resizing later)\n",
    "X = np.zeros((len(training_files), img_size[0], img_size[1]))\n",
    "y = np.zeros(len(training_files))\n",
    "\n",
    "# Step through all the files\n",
    "current_idx = 0;\n",
    "for fs in training_files:\n",
    "    # Parse the filename (we only really care about extracting the object class)\n",
    "    x = re.search(\"\\d+\\.\\d+\\.(\\S+)\\.png\", fs)\n",
    "    \n",
    "    # Read the file\n",
    "    img = cv2.imread(fs)\n",
    "    img = np.squeeze(img[:,:,1]) # select the first color channel\n",
    "    \n",
    "    if (x.group(1) == '1'): # \"Car\"\n",
    "        X[current_idx,:,:] = img\n",
    "        y[current_idx] = 1\n",
    "        current_idx += 1\n",
    "    elif(x.group(1) == 'bg'): # Background\n",
    "        X[current_idx,:,:] = img\n",
    "        y[current_idx] = 0\n",
    "        current_idx += 1\n",
    "\n",
    "num_cars = np.count_nonzero(y==1)\n",
    "num_bg = np.count_nonzero(y==0)\n",
    "print(\"found {} cars and {} background images\".format(num_cars, num_bg))\n",
    "\n",
    "# Equalize the class probabilities for training (delete a random subset)\n",
    "# We do this now and not earlier because we don't know fully what we are going to get out of the directory apriori\n",
    "num_bg_to_delete = np.round(0).astype('int')\n",
    "np.random.seed(2019)\n",
    "if (num_bg_to_delete):\n",
    "    print(\"Deleting \", num_bg_to_delete, \" background images\")\n",
    "    bg_idx = np.nonzero(y==0)[0]\n",
    "    np.random.shuffle(bg_idx)\n",
    "    to_delete = bg_idx[0:num_bg_to_delete]\n",
    "    y = np.delete(y,to_delete)\n",
    "    X = np.delete(X,to_delete, axis=0)\n",
    "    \n",
    "num_cars = np.count_nonzero(y==1)\n",
    "num_bg = np.count_nonzero(y==0)\n",
    "print(\"After class equalization, there are {} cars and {} background images\".format(num_cars, num_bg))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_to_show = 25\n",
    "imgs_per_col = 5\n",
    "plt.figure(figsize=(10,10)) \n",
    "for i in range(0, imgs_to_show):\n",
    "    plt.subplot(imgs_to_show/imgs_per_col, imgs_per_col, i+1)\n",
    "    plt.imshow(X[i,:,:], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(y[i])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_float = X.astype('float32')\n",
    "\n",
    "print(X_float[0,:,:].max())\n",
    "print(X_float[0,:,:].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM (on pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_pixel_svm:\n",
    "    X_flat = X_float.reshape((len(X), -1))\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X_flat, y, test_size=0.25, random_state=23)\n",
    "\n",
    "    parameters = [\n",
    "        {'kernel':['rbf'], 'gamma':np.logspace(-8, -5, 10)}\n",
    "    ]\n",
    "    clf=svm.SVC()\n",
    "    svm_pixels=model_selection.GridSearchCV(estimator=clf, param_grid=parameters, cv=4, n_jobs=-1);\n",
    "    svm_pixels.fit(X_train,y_train)\n",
    "    print(\"Best estimator:\\n\", svm_pixels.best_estimator_)\n",
    "\n",
    "    #Check performance\n",
    "    y_pred = svm_pixels.predict(X_test)\n",
    "\n",
    "    print(\"Accuracy score:\\n\", metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_pixel_svm:\n",
    "    y_probs = svm_pixels.predict(X_test) #y_probs is class probabilities\n",
    "\n",
    "    X_test_imgs = X_test.reshape((-1, 64, 64, 1))\n",
    "    plot_support.plot_misclassifications(X_test_imgs, y_test, y_probs, file_prefix=\"svm_pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM (on features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, generate the feature vectors for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_feature_svm:\n",
    "    from feature_extraction import generate_feature_vector\n",
    "    # Parameters\n",
    "    num_cells = 8\n",
    "    num_orientations = 8\n",
    "    frequencies = [0.125, 0.25, 0.5, 1, 2, 4, 8] # Guesses\n",
    "    sigmas = [1,2,3]\n",
    "    num_features = generate_feature_vector( X[0,:,:], num_cells, num_orientations, frequencies, sigmas  ).size #just to get the size of the feature vector\n",
    "\n",
    "    X_features = np.zeros((X.shape[0], num_features))\n",
    "    for i in range(0, X.shape[0]):\n",
    "        X_features[i, :] = generate_feature_vector( X[i,:,:], num_cells, num_orientations, frequencies, sigmas  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, train a classifier using these features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_feature_svm:\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X_features, y, test_size=0.25, random_state=23)\n",
    "    parameters = [\n",
    "        {'kernel':['rbf'], 'gamma':np.logspace(-8, -5, 10)}\n",
    "    ]\n",
    "    clf=svm.SVC()\n",
    "    cv_clf=model_selection.GridSearchCV(estimator=clf, param_grid=parameters, cv=4, n_jobs=-1);\n",
    "    cv_clf.fit(X_train,y_train)\n",
    "    print(\"Best estimator:\\n\", cv_clf.best_estimator_)\n",
    "\n",
    "    #Check performance\n",
    "    y_pred = cv_clf.predict(X_test)\n",
    "\n",
    "    print(\"Accuracy score:\\n\", metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, format the data.  It is strangely extremely important to scale the data to between 0 and 1 (it started as an 8 bit image, with a max value of 255).  Note that the CNN expects each chip to be 3D - even if the third dimension (channel) is 1.  We then slice the data (randomly) into training and holdout sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_for_cnn = X_float/255\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(X_for_cnn.reshape(X_for_cnn.shape[0], X_for_cnn.shape[1], X_for_cnn.shape[2], 1), y, test_size=0.15, random_state=23)\n",
    "input_shape = (x_train.shape[1], x_train.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if run_cnn:\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Conv2D(filters=64, kernel_size=(4,4), input_shape=input_shape))\n",
    "    cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    cnn_model.add(Conv2D(filters=32, kernel_size=(4,4)))\n",
    "    cnn_model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "    cnn_model.add(Dense(128, activation='relu'))\n",
    "    cnn_model.add(Dropout(0.2))\n",
    "    cnn_model.add(Dense(2,activation='softmax'))\n",
    "    cnn_model.compile(optimizer='adam', \n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    cnn_model.fit(x=x_train,y=y_train, epochs=10)\n",
    "    \n",
    "    score = cnn_model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    y_test_hat = cnn_model.predict(x_test)[:,1]\n",
    "    precision, recall, _ = metrics.precision_recall_curve(y_test, y_test_hat)\n",
    "    step_kwargs = {'step': 'post'}\n",
    "    plt.step(recall, precision, color='b', alpha=0.2,\n",
    "             where='post')\n",
    "    plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('2-class Precision-Recall curve');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision/recall plotting was taken from the [scikit-learn documentation](https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the misclassifications from the holdout set.  Specifically, we'll look at (up to) 10 false positives and false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_cnn:\n",
    "    #import importlib\n",
    "    #importlib.reload(plot_support)\n",
    "    y_probs = cnn_model.predict(x_test) #y_probs is class probabilities\n",
    "    y_probs = np.squeeze(y_probs[:,1])\n",
    "\n",
    "    plot_support.plot_misclassifications(x_test, y_test, y_probs, file_prefix=\"cnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning from ResNet50\n",
    "[Kaggle Example](https://www.kaggle.com/dansbecker/transfer-learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_resnet:\n",
    "    X_color = X.astype('float64').reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
    "    X_color = np.tile(X_color, (1,1,1,3))\n",
    "    X_color /= 3\n",
    "\n",
    "    x_train, x_test, y_train, y_test = model_selection.train_test_split(X_color, y, test_size=0.15, random_state=23)\n",
    "    input_shape = (x_train.shape[1], x_train.shape[2], 3)\n",
    "\n",
    "    transfer_model = Sequential()\n",
    "    transfer_model.add(ResNet50(include_top=False, input_shape=input_shape, pooling='avg', weights='imagenet'))\n",
    "    transfer_model.add(Dense(2,activation='softmax'))\n",
    "    transfer_model.layers[0].trainable = False\n",
    "\n",
    "    transfer_model.compile(optimizer='sgd', \n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    transfer_model.fit(x=x_train,y=y_train, epochs=3)\n",
    "\n",
    "    score = transfer_model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_resnet:\n",
    "    y_probs = transfer_model.predict(x_test) #y_probs is class probabilities\n",
    "    y_probs = np.squeeze(y_probs[:,1])\n",
    "\n",
    "    plot_support.plot_misclassifications(x_test, y_test, y_probs, file_prefix=\"resnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run classifiers on test images (localization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation import run_sliding_window\n",
    "from non_maximal_suppression import do_non_max_suppression\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "test_img_list = [\"00000014_ir.png\", \"00000017_ir.png\", \"00000021_ir.png\", \"00000024_ir.png\"]\n",
    "classifier_name = [\"SVM (pixels)\", \"SVM (features)\", \"CNN\", \"ResNet transfer\"]\n",
    "\n",
    "# Loop over all the test images\n",
    "for ti in test_img_list:\n",
    "    # Read in image data and format it for the various classifiers\n",
    "    test_img = cv2.imread(os.path.join(data_dir, ti ), cv2.IMREAD_GRAYSCALE)\n",
    "    partitioned_image, bboxes_vertices = run_sliding_window(test_img, 8, 64, 64)\n",
    "    bboxes_array = np.asarray(bboxes_vertices).reshape((-1,4))\n",
    "    partitioned_image_flat = partitioned_image.reshape((-1, 64, 64, 1))\n",
    "\n",
    "    partitioned_image_for_svm = partitioned_image_flat.reshape((-1, 64*64))\n",
    "\n",
    "    partitioned_image_for_cnn = partitioned_image_flat.astype('float32')\n",
    "    partitioned_image_for_cnn /= 255\n",
    "\n",
    "    partitioned_image_for_transfer = np.tile(partitioned_image_flat.astype('float64'), (1,1,1,3))\n",
    "    partitioned_image_for_transfer /= 3\n",
    "    \n",
    "    # Run each of the enabled classifiers\n",
    "    class_flat = np.zeros((4,partitioned_image_flat.shape[0]))\n",
    "    if run_pixel_svm:\n",
    "        class_flat[0,:] = svm_pixels.predict(partitioned_image_for_svm)\n",
    "    if run_cnn:\n",
    "        class_flat[2,:] = cnn_model.predict(partitioned_image_for_cnn)[:,1]\n",
    "    if run_resnet:\n",
    "        class_flat[3,:] = transfer_model.predict(partitioned_image_for_transfer)[:,1]\n",
    "    \n",
    "    # Plot results for each classifier\n",
    "    for i in range(0,4):\n",
    "        # Detection logic\n",
    "        class_flat_single = np.squeeze(class_flat[i,:])\n",
    "        detection_idx = np.nonzero(class_flat_single>0.97)[0]\n",
    "        detection_boxes = bboxes_array[detection_idx,:]\n",
    "        detection_probs = class_flat_single[detection_idx]\n",
    "        \n",
    "        plt.figure(figsize=(24,8))\n",
    "        \n",
    "        plt.subplot(1,3,1)\n",
    "        plt.imshow(class_flat_single.reshape((partitioned_image.shape[0], partitioned_image.shape[1])), cmap='magma') #show map of probabilities\n",
    "        plt.axis('off')\n",
    "        plt.title('{}: Class estimate heatmap'.format(classifier_name[i]))\n",
    "        \n",
    "        plt.subplot(1,3,2)\n",
    "        plt.imshow(test_img, cmap='gray')\n",
    "        for b in detection_boxes:\n",
    "            rect = patches.Rectangle(b[0:2],64,64,linewidth=4,edgecolor='g',facecolor='none')\n",
    "            plt.gca().add_patch(rect)\n",
    "        plt.axis('off')\n",
    "        plt.title('{}: Before non-maximal supression'.format(classifier_name[i]))\n",
    "\n",
    "        plt.subplot(1,3,3)\n",
    "        picked_boxes = do_non_max_suppression(detection_boxes, detection_probs)\n",
    "        plt.imshow(test_img, cmap='gray')\n",
    "        for b in picked_boxes:\n",
    "            rect = patches.Rectangle(b[0:2],64,64,linewidth=4,edgecolor='g',facecolor='none')\n",
    "            plt.gca().add_patch(rect)\n",
    "        plt.axis('off')\n",
    "        plt.title('{}: After non-maximal supression'.format(classifier_name[i]))\n",
    "        plt.savefig('{} - with {}.png'.format(ti, classifier_name[i]))\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
